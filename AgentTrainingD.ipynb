{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time \n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import collections\n",
    "\n",
    "import progressbar\n",
    "from progressbar import FormatLabel, Percentage, Bar, ETA\n",
    "\n",
    "\n",
    "from data_loader import DataLoader\n",
    "#import viewer functions\n",
    "from dataViewer import plotTraj, animatePreview, animateLoc, animateTraj\n",
    "\n",
    "import hdf5_utils as hd\n",
    "from simulation import Agent, Engine\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(arr1, arr2, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    size = len(arr1)\n",
    "    for i in range(0, size, n):\n",
    "        yield arr1[i:min(i + n, size)], arr2[i:min(i + n, size)]\n",
    "        \n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#hidden_layer = [32, 32, 64, 128, 128, 40]\n",
    "\n",
    "#hidden_layer = [ 128, 128, 40, 32, 32, 64,]\n",
    "#hidden_layer = [ 50, 30, 10, 20, 30, 30,]\n",
    "#hidden_layer = [28 ,20, 10, 10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_traindata = True\n",
    "\n",
    "dset = {'neighbors':5,\n",
    "        'ret_vel':True,\n",
    "        'nn_vel': True,\n",
    "        'truth_with_vel':True,\n",
    "        'shuffle':True,\n",
    "        'mode': \"wrap\",\n",
    "        'fps':16,\n",
    "        'name': \"ug-100-045\",\n",
    "       }\n",
    "\n",
    "\n",
    "\n",
    "param = {'input_s': 2+2*dset['ret_vel']  + dset['neighbors']*(2+2*dset['nn_vel']), #(number_nei+1)*4,\n",
    "         'hidden_s': [32, 32, 64, 128, 128, 40],\n",
    "         'output_s': 2+dset['truth_with_vel']*2,\n",
    "         'epochs':30,\n",
    "         'batch_size':10,\n",
    "         'lr':1e-3,\n",
    "         'decay':0.1,\n",
    "         'decay_step':5,\n",
    "         #'dtype':torch.float,\n",
    "         'device':torch.device(\"cuda:0\"),\n",
    "         'dataset':dset,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FPS = 16\n",
    "\n",
    "BG = \"Datasets/UG/ug.png\"\n",
    "\n",
    "PATH_1 = \"Datasets/UG/UG-roh_nachkorrigiert/ug-100-045.txt\"\n",
    "\n",
    "\n",
    "\n",
    "PATH = \"Datasets/AO/\"\n",
    "PATH = \"Datasets/UG/UG-roh_nachkorrigiert/\"\n",
    "PATH2 = \"data/HD5/\"\n",
    "fname = \"ao-360-400_combine\" #\"ao-240-400_combine\"\n",
    "fname = \"ug-100-045\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 96 persons\n",
      "Persons:  96\n",
      "Frame maximum : 1088\n",
      "Trainingdata has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zehndi/CNN/Projects/ai-team/hdf5_utils.py:126: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  val = (database.get('val/input').value, database.get('val/truth').value )\n",
      "/home/zehndi/CNN/Projects/ai-team/hdf5_utils.py:127: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  test = (database.get('test/input').value, database.get('test/truth').value )\n",
      "/home/zehndi/CNN/Projects/ai-team/hdf5_utils.py:128: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = DataLoader(PATH + dset['name'] + \".txt\")\n",
    "\n",
    "ds.load()\n",
    "\n",
    "print(\"Persons: \", ds.data.p.max())\n",
    "print(\"Frame maximum :\", ds.data.f.max() )\n",
    "\n",
    "\n",
    "sufix = \"_{}_{}_{}_{}_{}\".format(dset['neighbors'],\n",
    "                                 dset['shuffle'],\n",
    "                                 dset['truth_with_vel'],\n",
    "                                 dset['mode'],\n",
    "                                 dset['ret_vel']+dset['nn_vel'])\n",
    "\n",
    "\n",
    "f_name = PATH2+param['dataset']['name']+sufix+'.h5'\n",
    "\n",
    "if os.path.isfile(f_name) and load_traindata:\n",
    "\n",
    "    train, val, test, param['dataset'] = hd.load_trainingdata(f_name)\n",
    "    print(\"Trainingdata has been loaded\")\n",
    "\n",
    "else:\n",
    "    f_x = ds.flip_x\n",
    "\n",
    "    augmentation = []#[f_x]\n",
    "    train, val, test = ds.get_train_data(dset['neighbors'], \n",
    "                                         augmentation=augmentation,\n",
    "                                         ret_vel=dset['ret_vel'],\n",
    "                                         nn_vel=dset['nn_vel'],\n",
    "                                         shuffle=dset['shuffle'],\n",
    "                                         truth_with_vel=dset['truth_with_vel'],\n",
    "                                         mode=dset['mode'])\n",
    "    dset['date'] = time.ctime()\n",
    "    dset['creator'] = 'zehndiii'\n",
    "    dset['augmentation'] = str(augmentation)\n",
    "    param['dataset'] = dset\n",
    "    \n",
    "    hd.save_trainingdata(f_name, param, train, val, test)\n",
    "    print(\"Training data saved to : {}\".format(PATH2+fname+sufix+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/HD5/ug-100-045_5_True_True_wrap_2.h5/\n",
      "|     Size: 4.38MB\n",
      "|     @augmentation: [<bound method DataLoader.flip_x of <data_loader.DataLoader object at 0x7f0a00fc9e80>>]\n",
      "|     @creator: zehndiii\n",
      "|     @date: Sun Nov 22 02:03:45 2020\n",
      "|     @fps: 16\n",
      "|     @mode: wrap\n",
      "|     @name: ug-100-045\n",
      "|     @neighbors: 5\n",
      "|     @nn_vel: True\n",
      "|     @ret_vel: True\n",
      "|     @shuffle: True\n",
      "|     @truth_with_vel: True\n",
      "|\n",
      "|Group: test \n",
      "|     |-----Dataset: input           - Shape: (9711, 24) float32\n",
      "|     |-----Dataset: truth           - Shape: (9711, 4) float32\n",
      "|\n",
      "|Group: train \n",
      "|     |-----Dataset: input           - Shape: (29133, 24) float32\n",
      "|     |-----Dataset: truth           - Shape: (29133, 4) float32\n",
      "|\n",
      "|Group: val \n",
      "|     |-----Dataset: input           - Shape: (9712, 24) float32\n",
      "|     |-----Dataset: truth           - Shape: (9712, 4) float32\n"
     ]
    }
   ],
   "source": [
    "hd.print_stats(PATH2+param['dataset']['name']+sufix+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format training data as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_input, t_truth = train\n",
    "v_input, v_truth = val\n",
    "test_input, test_truth = test\n",
    "\n",
    "t_i = torch.from_numpy(t_input).to(param['device'])\n",
    "t_t = torch.from_numpy(t_truth).to(param['device'])\n",
    "\n",
    "v_i = torch.from_numpy(v_input).to(param['device'])\n",
    "v_t = torch.from_numpy(v_truth).to(param['device'])\n",
    "\n",
    "test_i = torch.from_numpy(test_input).to(param['device'])\n",
    "test_t = torch.from_numpy(test_truth).to(param['device'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size[0]) \n",
    "        \n",
    "        #self.fc_hidden = []\n",
    "        #for i in range(len(hidden_size)-1):\n",
    "        self.fc_hidden_1 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.fc_hidden_2 = nn.Linear(hidden_size[1], hidden_size[2])\n",
    "        self.fc_hidden_3 = nn.Linear(hidden_size[2], hidden_size[3])\n",
    "        \n",
    "        self.fc_hidden_4 = nn.Linear(hidden_size[3], hidden_size[4])\n",
    "        self.fc_hidden_5 = nn.Linear(hidden_size[4], hidden_size[5])\n",
    "\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size[-1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        #self.drop = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "     \n",
    "        out = self.relu(self.fc_in(x))\n",
    "        \n",
    "        #for i in range(len(self.fc_hidden)):\n",
    "        #    out = self.relu(self.fc_hidden[i](out))\n",
    "        \n",
    "        out = self.relu(self.fc_hidden_1(out))\n",
    "        out = self.relu(self.fc_hidden_2(out))\n",
    "        out = self.relu(self.fc_hidden_3(out))\n",
    "        out = self.relu(self.fc_hidden_4(out))\n",
    "        #out = self.drop(out)\n",
    "        out = self.relu(self.fc_hidden_5(out))\n",
    "        \n",
    "        \n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = NeuralNet(param['input_s'], param['hidden_s'], param['output_s']).to(param['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose loss function - can be played around with\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=param['lr'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=param['decay_step'], gamma=param['decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss(t/v) : 20.33 / 61.77 | lr=0.001  16% |###                 | ETA:   0:06:02"
     ]
    }
   ],
   "source": [
    "\n",
    "d_len = t_i.shape[0]\n",
    "\n",
    "\n",
    "pbar = progressbar.ProgressBar(max_value=param['epochs'])\n",
    "widgets = [FormatLabel(''), ' ', Percentage(), ' ', Bar(), ' ', ETA()]\n",
    "pbar = progressbar.ProgressBar(widgets=widgets, maxval=param['epochs']*d_len)\n",
    "pbar.start()\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = [0.0]\n",
    "\n",
    "for t in range(param['epochs']):\n",
    "    \n",
    "    # Train on Batches\n",
    "    \n",
    "    p = np.random.permutation(len(t_i))\n",
    "    t_i = t_i[p]\n",
    "    t_t = t_t[p]\n",
    "    \n",
    "    for  y, (t_i_b, t_t_b) in  enumerate(batch(t_i, t_t, param['batch_size'])):\n",
    "        y_pred = model(t_i_b)\n",
    "       \n",
    "        loss = loss_fn(y_pred, t_t_b)\n",
    "\n",
    "        model.zero_grad()\n",
    "       \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        widgets[0] = FormatLabel('loss(t/v) : {:.4} / {:.4} | lr={:.4}'.format(loss.item(),\n",
    "                                                                            validation_loss[-1],\n",
    "                                                                            optimizer.param_groups[0]['lr']))\n",
    "        pbar.update(t*d_len+y*param['batch_size'])\n",
    "        \n",
    "        if y%10==9:\n",
    "            training_loss += [loss.cpu().detach().numpy()]\n",
    "    \n",
    "    # Test on validation\n",
    "    \n",
    "    loss = []\n",
    "    with torch.no_grad():\n",
    "        for v_i_b, v_t_b in batch(v_i, v_t, param['batch_size']):\n",
    "            y_pred = model(v_i_b)\n",
    "            loss += [loss_fn(y_pred, v_t_b).cpu().detach().numpy()]\n",
    "            pbar.update()\n",
    "    validation_loss.append( np.array(loss).mean() )\n",
    "    \n",
    "    scheduler.step()\n",
    "        \n",
    "\n",
    "pbar.finish()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss = np.array(training_loss)\n",
    "val_loss = np.array(validation_loss[1:])\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(train_loss))*10*param['batch_size']/d_len, train_loss, label=\"train_loss\")\n",
    "plt.semilogy(np.arange(len(val_loss)), val_loss, label=\"val_loss\" )\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(len(val_loss))\n",
    "print(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dat = []\n",
    "\n",
    "pbar = progressbar.ProgressBar(maxval=len(test_i))\n",
    "pbar.start()\n",
    "\n",
    "i = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (ti, tt) in zip(test_i, test_t):\n",
    "        pred = model(ti)\n",
    "        loss = loss_fn(pred, tt)\n",
    "        test_dat.append(loss.cpu().detach().numpy())\n",
    "     \n",
    "        if i%10:\n",
    "            pbar.update(i)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    pbar.finish()\n",
    "    \n",
    "test_dat = np.array(test_dat)\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(np.arange(len(test_dat)), test_dat)\n",
    "plt.semilogy(np.arange(len(test_dat)), smooth(test_dat, 100))\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/ Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH_M = \"data/model/\"\n",
    "f_name = \"data/model/model_paper_dropout.dat\"\n",
    "\n",
    "f_name = \"test.h5\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#hd.print_stats(f_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hd.save_torch(model, optimizer, f_name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zehndi/CNN/Projects/ai-team/hdf5_utils.py:164: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc_in): Linear(in_features=14, out_features=32, bias=True)\n",
       "  (fc_hidden_1): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (fc_hidden_2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (fc_hidden_3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc_hidden_4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_hidden_5): Linear(in_features=128, out_features=40, bias=True)\n",
       "  (fc_out): Linear(in_features=40, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model , param = hd.load_torch(f_name, NeuralNet)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# Singel agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_person = 50\n",
    "\n",
    "da = DataLoader(None)\n",
    "\n",
    "\n",
    "da.copy(ds)\n",
    "# crop the standing phase\n",
    "da.data = da.data[ da.data['f']>100]\n",
    "\n",
    "frames_o, pos_vel_o = da.person(test_person, )\n",
    "#frames, pos_vel = da.grab_roi(frames_o, pos_vel_o, x_pad=50)\n",
    "\n",
    "da.remove_person(test_person)\n",
    "\n",
    "print(frames_o[0], frames_o[-1])\n",
    "\n",
    "agent = Agent(model,\n",
    "              pos_vel_0=pos_vel_o[0],\n",
    "              frame_0=frames_o[0],\n",
    "              truth_with_vel=param['dataset']['truth_with_vel'],\n",
    "              device=param['device'],\n",
    "              id=1000+test_person )\n",
    "\n",
    "\n",
    "\n",
    "print(agent.id )\n",
    "print(pos_vel_o[0])\n",
    "\n",
    "\n",
    "sim = Engine(da, agents=[agent],\n",
    "             stop_agent=True,\n",
    "             nn=param['dataset']['neighbors'],\n",
    "             ret_vel=param['dataset']['ret_vel'],\n",
    "             nn_vel=param['dataset']['nn_vel'],\n",
    "             truth_with_vel=param['dataset']['truth_with_vel'],\n",
    "             mode=param['dataset']['mode'],\n",
    "            )\n",
    "\n",
    "sim.run(301, 1000)#frames_o[-1], )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dp = DataLoader(None)\n",
    "dp.copy(sim.ds)\n",
    "dp.append_person(test_person, frames_o, pos_vel_o[:,:2], vel=pos_vel_o[:,2:] )\n",
    "\n",
    "plotTraj(dp,  boundaries=[-600, 600, -400, 400],\n",
    "         people=None,\n",
    "         ai=[ 1000+test_person],#test_person,\n",
    "         legend=False,\n",
    "         title=\"Trajectories\",\n",
    "         path=\"trajectories.png\",\n",
    "         save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animateLoc(dp, frame_start=frames_o[0], frame_stop=frames_o[-1],ai=[1000+test_person],\n",
    "             boundaries=[-800, 600, -200, 400], step=1, fps=16, title=\"ululululu\", save=False)\n",
    "display(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animatePreview(dp, boundaries=[-600, 600, -250, 150], step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animateTraj(dp, frame_start=frames_o[0], frame_stop=frames_o[-1], boundaries=[-600, 600, -250, 150], step=1, fps=16, title=\"Trajectory Animation\")\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['input_s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi agent simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_id = np.array([10, 20, 30, 35, 40, ]) #120, 160, 200])\n",
    "\n",
    "agents_id, _ = ds.frame(201)\n",
    "\n",
    "\n",
    "\n",
    "da = DataLoader(None)\n",
    "\n",
    "da.copy(ds)\n",
    "da.data = da.data[ da.data['f']>200]\n",
    "\n",
    "\n",
    "agents_id = da.data['p'].unique()\n",
    "\n",
    "agents = []\n",
    "\n",
    "frame_max = 0\n",
    "\n",
    "for test_person in agents_id:\n",
    "\n",
    "    #frames_o, pos_vel_o =  da.person( test_person, )\n",
    "    frames_o, pos_vel_o =  da.grab_roi( *da.person(test_person, ), x_pad=20 )\n",
    "\n",
    "    da.remove_person(test_person)\n",
    "\n",
    "    \n",
    "    if len(frames_o)<1:\n",
    "        continue\n",
    "    \n",
    "    frame_max = max(frames_o[-1], frame_max)\n",
    "    \n",
    "    agents += [Agent(model,\n",
    "                     pos_vel_0=pos_vel_o[0],\n",
    "                     frame_0=frames_o[0],\n",
    "                     truth_with_vel=param['dataset']['truth_with_vel'],\n",
    "                     device=param['device'],\n",
    "                     id=1000+test_person )]\n",
    "\n",
    "#for id in da.data['p'].unique():\n",
    "#    da.remove_person(id)\n",
    "\n",
    "print(\"People in Dataset: \", da.persons)\n",
    "print(\"Agents in Dataset: \", len(agents))\n",
    "\n",
    "sim = Engine(da, agents=agents,\n",
    "             nn=param['dataset']['neighbors'],\n",
    "             ret_vel=param['dataset']['ret_vel'],\n",
    "             nn_vel=param['dataset']['nn_vel'],\n",
    "             truth_with_vel=param['dataset']['truth_with_vel'],\n",
    "             mode=param['dataset']['mode'],\n",
    "             stop_agent=True)\n",
    "\n",
    "sim.run(0,frame_max, )\n",
    "\n",
    "\n",
    "\n",
    "dp = DataLoader(None)\n",
    "dp.copy(sim.ds)\n",
    "\n",
    "\n",
    "plotTraj(dp,  boundaries=[-600, 600, -400, 400],\n",
    "         people=None,\n",
    "         ai=agents_id+1000,\n",
    "         legend=False,\n",
    "         title=\"Trajectories\",\n",
    "         path=\"trajectories.png\",\n",
    "         save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ani = animateLoc(dp, frame_start=0, frame_stop=700,ai=agents_id+1000,\n",
    "             boundaries=[-800, 600, -200, 400], step=1, fps=16, title=\"ululululu\", save=False)\n",
    "display(ani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def load_torch(f_name, MODEL_class):\n",
    "    \n",
    "    db = h5py.File(f_name, 'r')\n",
    "    \n",
    "    params = hd.load_attrs(db)\n",
    "    db_params = hd.load_attrs(db['dataset'])\n",
    "    \n",
    "    mod = db['model']\n",
    "    mod_params = hd.load_attrs(mod)\n",
    "    \n",
    "    params['dataset'] = db_params\n",
    "    params['input_s'] = mod_params['input_s'],\n",
    "    params['hidden_s'] = mod_params['hidden_s'],\n",
    "    params['output_s'] = mod_params['output_s'],\n",
    "    params['device'] = torch.device(params['device'])\n",
    "    \n",
    "    \n",
    "    model = MODEL_class(mod_params['input_s'], mod_params['hidden_s'], mod_params['output_s'])\n",
    "    \n",
    "    \n",
    "    stat = collections.OrderedDict() \n",
    "    for l in mod_params['layers']:\n",
    "        layer_param = hd.load_attrs(mod[l])\n",
    "        stat[l] = torch.from_numpy(mod.get(l).value,).to(layer_param['device'])\n",
    "    \n",
    "    db.close()\n",
    "    \n",
    "    model.load_state_dict(stat)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model, params\n",
    "\n",
    "\n",
    "def save_torch(model, optimizer, f_name, param, crator=\"zehndiii\"):\n",
    "    #TODO Apend mode\n",
    "    #TODO no overwrite\n",
    "    \n",
    "    db = h5py.File(f_name, 'w')\n",
    "    \n",
    "    # write general settings\n",
    "    hd.write_attrs(db, {'creator':\"zehndiii\",       # write general attributes\n",
    "                      'date':time.ctime(),\n",
    "                      'epochs':param['epochs'],\n",
    "                      'batch_size':param['batch_size'],\n",
    "                #'optimizer':str(type(optimizer)),\n",
    "                      'lr':param['lr'],\n",
    "                      'decay':param['decay'],\n",
    "                      'decay_step':param['decay_step'],\n",
    "                      'device':str(param['device'])\n",
    "                       })\n",
    "    \n",
    "    \n",
    "\n",
    "    # write dataset settings\n",
    "    dataset = db.create_group('/dataset')\n",
    "    \n",
    "    hd.write_attrs(dataset, param['dataset'])\n",
    "    \"\"\"\n",
    "    {'creator':creator,       # write general attributes\n",
    "                      'date':date,\n",
    "                      'neighbors':number_nei,\n",
    "                      'augmentation':str(augmentation),\n",
    "                      'shuffle':shuffle,\n",
    "                      'truth_with_vel':truth_with_vel,\n",
    "                      'mode':mode,\n",
    "                      'fps':FPS\n",
    "                     }\n",
    "    \"\"\"\n",
    "    \n",
    "    # write model and settings\n",
    "    mod = db.create_group('/model')\n",
    "   \n",
    "    stat = model.state_dict()\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    for k, v in stat.items():\n",
    "        \n",
    "        layers += [k]\n",
    "        \n",
    "        dat = v.cpu().detach().numpy()\n",
    "        ds = mod.create_dataset( name=k,shape=v.shape, \n",
    "                                         dtype=dat.dtype,\n",
    "                                         data=dat, compression=\"lzf\" )\n",
    "\n",
    "        hd.write_attrs(ds, {'device':str(v.device.type),\n",
    "                            'dtype':str(v.dtype),\n",
    "                         })\n",
    "    \n",
    "    hd.write_attrs(mod, {'input_s':param['input_s'],\n",
    "                         'hidden_s':param['hidden_s'],\n",
    "                         'output_s':param['output_s'],\n",
    "                         'layers':layers,\n",
    "                         })\n",
    "    \n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf 5 dump\n",
    "\n",
    "f_name = PATH2+param['dataset']['name']+sufix+'.h5'\n",
    "\n",
    "def save_trainingdata(f_name, train, val, test ):\n",
    "\n",
    "\n",
    "    database = h5py.File(f_name, 'w')\n",
    "\n",
    "    hd.write_attrs(database, param['dataset'] ) \n",
    "    \n",
    "    train_h = database.create_group('/train')\n",
    "    train_h.create_dataset( name='input',shape=train[0].shape, \n",
    "                                         dtype=train[0].dtype,\n",
    "                                         data=train[0], compression=\"lzf\" )\n",
    "    train_h.create_dataset( name='truth',shape=train[1].shape, \n",
    "                                         dtype=train[1].dtype,\n",
    "                                         data=train[1], compression=\"lzf\" )\n",
    "    val_h = database.create_group('/val')\n",
    "    val_h.create_dataset( name='input',shape=val[0].shape, \n",
    "                                         dtype=val[0].dtype,\n",
    "                                         data=val[0], compression=\"lzf\" )\n",
    "    val_h.create_dataset( name='truth',shape=val[1].shape, \n",
    "                                         dtype=val[1].dtype,\n",
    "                                         data=val[1], compression=\"lzf\" )\n",
    "    test_h = database.create_group('/test')\n",
    "    test_h.create_dataset( name='input',shape=test[0].shape, \n",
    "                                         dtype=test[0].dtype,\n",
    "                                         data=test[0], compression=\"lzf\" )\n",
    "    test_h.create_dataset( name='truth',shape=test[1].shape, \n",
    "                                         dtype=test[1].dtype,\n",
    "                                         data=test[1], compression=\"lzf\" )\n",
    "\n",
    "    database.close()\n",
    "    print(\"Training data saved to : {}\".format(PATH2+fname+sufix+'.h5'))\n",
    "    \n",
    "def load_trainingdata(file_name):\n",
    "    database = h5py.File(file_name, 'r')                  # open db\n",
    "\n",
    "    param['dataset'] = hd.load_attrs(database)                        # print attrs if debug\n",
    "\n",
    "    train = (database.get('train/input').value, database.get('train/truth').value )\n",
    "    val = (database.get('val/input').value, database.get('val/truth').value )\n",
    "    test = (database.get('test/input').value, database.get('test/truth').value )\n",
    "\n",
    "    database.close()\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/model/model_paper_dropout.dat\")\n",
    "load_path = \"data/model/model_paper_dropout.dat\"\n",
    "\n",
    "model = NeuralNet(D_in, hidden_layer, D_out).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ai = sim.agents[0]\n",
    "tr = np.vstack( ai.traj )\n",
    "\n",
    "print(\"agent\")\n",
    "print(tr[:5])\n",
    "\n",
    "print(ai.pos)\n",
    "frames, traj = sim.ds.person(test_person+1000)\n",
    "\n",
    "print(\"dataset\")\n",
    "#print(frames[:])\n",
    "print(traj[:5])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "offset = 0\n",
    "end = -1\n",
    "plt.plot(tr[:,0], tr[:,1]) \n",
    "\n",
    "\n",
    "\n",
    "plt.plot(traj[offset: end,0], traj[offset:end,1])\n",
    "\n",
    "print(frames[offset])\n",
    "\n",
    "#plt.xlim([-600, 600])\n",
    "#plt.ylim([-150, 150])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "[[-342.531 -3.04867 -1.024000000000342 4.645119999999999]\n",
    " [-332.4825439453125 -3.1519365310668945 0.6280288696289062\n",
    "  -0.006454154849052429]\n",
    " [-322.0271301269531 -2.130854606628418 0.6534633636474609\n",
    "  0.06381762027740479]\n",
    " [-312.77081298828125 -3.785721778869629 0.5785198211669922\n",
    "  -0.10342919826507568]\n",
    " [-302.70819091796875 -2.7985124588012695 0.6289138793945312\n",
    "  0.06170058250427246]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "#define network\n",
    "\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    \n",
    "    torch.nn.Linear(D_in, 50), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 10),\n",
    "    \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Dropout(p=0.1),\n",
    "    \n",
    "    torch.nn.Linear(50, 30),\n",
    "    \n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Dropout(p=0.1),\n",
    "    \n",
    "    torch.nn.Linear(30, D_out), \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "hidden_size = 28#50\n",
    "hidden_size2 = 20\n",
    "hidden_size3 = 10#50\n",
    "hidden_size4 = 10\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size2, hidden_size3, hidden_size4, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size2) \n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "         \n",
    "        out = self.drop( self.fc3(out) )\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(D_in, hidden_size, hidden_size2, hidden_size3, hidden_size4,D_out).to(device)\n",
    "\n",
    "\n",
    "#if device.type.startswith(\"cuda\"):\n",
    "#    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.ModuleDict({\n",
    "            'lstm': torch.nn.LSTM(\n",
    "                input_size=D_in,    # 45, see the data definition\n",
    "                hidden_size=l_o,  # Can vary\n",
    "            ),\n",
    "            'linear1': torch.nn.Linear(\n",
    "                in_features=l_o,\n",
    "                out_features=D_out)\n",
    "        })\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # From [batches, seqs, seq len, features]\n",
    "        # to [seq len, batch data, features]\n",
    "        x = x.view(x_seq_len, -1, x_features)\n",
    "       \n",
    "        # Data is fed to the LSTM\n",
    "        out, _ = self.model['lstm'](x)\n",
    "        \n",
    "\n",
    "        # From [seq len, batch, num_directions * hidden_size]\n",
    "        # to [batches, seqs, seq_len,prediction]\n",
    "        out = out.view(x_batches, x_seqs, x_seq_len, -1)\n",
    "      \n",
    "\n",
    "        # Data is fed to the Linear layer\n",
    "        out = self.model['linear1'](out)\n",
    "       \n",
    "\n",
    "        # The prediction utilizing the whole sequence is the last one\n",
    "        y_pred = out[:, :, -1].unsqueeze(-1)\n",
    "       \n",
    "\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = Model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
